{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekly exercise: Convolutional Neural Network\n",
    "\n",
    "IN5400 / IN9400 MACHINE LEARNING FOR IMAGE ANALYSIS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Task1'></a>\n",
    "### Task1: Calculate the theoretical receptive field\n",
    "---\n",
    "\n",
    "You shall implement the function \"receptive_field\" and use it to calculate the receptive field for 5 different convolutional neural network architectures. When evaluating the receptive field, the image size (resolution) and the size of the objects of interest is important to consider.\n",
    "\n",
    "\n",
    "- Receptive field: ùëÖ \n",
    "- Filter size: ùêπ\n",
    "- Stride: S\n",
    "- Layer index: ùëò\n",
    "- $ R^{0}=1 $ Receptive field of input data \n",
    "\n",
    "<b>Note:</b> Superscript indicate layer index and not the exponent\n",
    "\n",
    "Equation (1)\n",
    "\n",
    " $$R^k = R^{k-1} + \\bigg[ (F^k -1)\\cdot \\prod_{i=1}^{k-1} S^i      \\bigg] $$\n",
    " \n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"images/receptive_field2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def receptive_field(f, s):\n",
    "    # Implement equation(1)\n",
    "    \n",
    "    # Inputs:\n",
    "    # f (list): Filter size for each layer\n",
    "    # s (list): Stride for each layer\n",
    "    \n",
    "    # Output\n",
    "    # R: The calculated receptive field for each layer as a numpy array\n",
    "    \n",
    "    # ToDo: \n",
    "    R = None\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the architectures\n",
    "\n",
    "# Architecture1\n",
    "A1_filterSize = [3, 3, 3, 3, 3, 3]\n",
    "A1_stride     = [1, 1, 1, 1, 1, 1]\n",
    "A1_Recept     = receptive_field(A1_filterSize, A1_stride)\n",
    "\n",
    "# Architecture2\n",
    "A2_filterSize = [3, 3, 3, 3, 3, 3]\n",
    "A2_stride     = [2, 1, 2, 1, 2, 1]\n",
    "A2_Recept     = receptive_field(A2_filterSize, A2_stride)\n",
    "\n",
    "# Architecture3\n",
    "A3_filterSize = [3, 3, 3, 3, 3, 3]\n",
    "A3_stride     = [2, 2, 2, 2, 2, 2]\n",
    "A3_Recept     = receptive_field(A3_filterSize, A3_stride)\n",
    "\n",
    "# Architecture4\n",
    "A4_filterSize = [5, 5, 5, 5, 5, 5]\n",
    "A4_stride     = [1, 1, 1, 1, 1, 1]\n",
    "A4_Recept     = receptive_field(A4_filterSize, A4_stride)\n",
    "\n",
    "# Architecture5\n",
    "A5_filterSize = [5, 5, 5, 5, 5, 5]\n",
    "A5_stride     = [2, 1, 2, 1, 2, 1]\n",
    "A5_Recept     = receptive_field(A5_filterSize, A5_stride)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.plot(A1_Recept, 'r', label='Architecture 1')\n",
    "plt.plot(A2_Recept, 'b', label='Architecture 2')\n",
    "plt.plot(A3_Recept, 'g', label='Architecture 3')\n",
    "plt.plot(A4_Recept, 'k', label='Architecture 4')\n",
    "plt.plot(A5_Recept, 'm', label='Architecture 5')\n",
    "plt.ylabel('Receptive field  (R)', fontsize=18)\n",
    "plt.xlabel('Layer $k$', fontsize=18)\n",
    "ax.grid()\n",
    "plt.ylim([0, 140])\n",
    "plt.xlim([0, 6])\n",
    "ax.legend(loc='upper left', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task2: Convolution\n",
    "\n",
    "---\n",
    "\n",
    "You are given an input image (x), kernel (w) and bias (b). Your task is to evaluate\n",
    "the shaded pixel in the image after the convolution. The origin of the\n",
    "kernel is the shaded pixel. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/x_w_b.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task3: Channel dimention of activation maps\n",
    "\n",
    "What is the relation between the channel dimention in an activation map and the filter bank?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Task4: Spatial size of the activation map \n",
    "\n",
    "Given an activation map with shape $[N_c=128, N_h=225, N_w=225]$ and a kernal with shape $[F_c=128, F_h=5, F_w=5 ]$, what will the spatial size of the next layer's activation map be if we pad with $P=2$ and use stride of $S=2$?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
